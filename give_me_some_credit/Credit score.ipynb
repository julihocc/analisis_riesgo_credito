{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d4dc22bf2a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cs-training1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.to_csv('./cs-training1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cs-training1.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('cs-training.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "**SeriousDlqin2yrs** Person experienced 90 days past due delinquency or worse\n",
    "\n",
    "**RevolvingUtilizationOfUnsecuredLines**: Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits\n",
    "\n",
    "**age**\tAge of borrower in years\n",
    "\n",
    "**NumberOfTime30-59DaysPastDueNotWorse**: Number of times borrower has been 30-59 days past due but no worse in the last 2 years.\n",
    "\n",
    "**DebtRatio**: Monthly debt payments, alimony,living costs divided by monthy gross income\n",
    "\n",
    "**MonthlyIncome**: Monthly income\n",
    "\n",
    "**NumberOfOpenCreditLinesAndLoans**: Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)\n",
    "\n",
    "**NumberOfTimes90DaysLate**: Number of times borrower has been 90 days or more past due.\n",
    "\n",
    "**NumberRealEstateLoansOrLines**: Number of mortgage and real estate loans including home equity lines of credit\n",
    "\n",
    "**NumberOfTime60-89DaysPastDueNotWorse**: Number of times borrower has been 60-89 days past due but no worse in the last 2 years.\n",
    "\n",
    "**NumberOfDependents**: Number of dependents in family excluding themselves (spouse, children etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanCol = []\n",
    "for i in range(len(data.columns)):\n",
    "    cleanCol.append(data.columns[i].replace('-', ''))\n",
    "    \n",
    "data.columns = cleanCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecificAndPutMedian(data, first = 98, second = 96):\n",
    "    New = []\n",
    "    med = data.median()\n",
    "    for val in data:\n",
    "        if ((val == first) | (val == second)):\n",
    "            New.append(med)\n",
    "        else:\n",
    "            New.append(val)\n",
    "            \n",
    "    return New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_freq():\n",
    "    ncount = len(data)\n",
    "\n",
    "    ax2=ax.twinx()\n",
    "\n",
    "    ax2.yaxis.tick_left()\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "    ax.yaxis.set_label_position('right')\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "\n",
    "    ax2.set_ylabel('Frequency [%]')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    ax2.set_ylim(0,100)\n",
    "    ax2.grid(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a sense of how balanced or imbalanced is the outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = data.SeriousDlqin2yrs ,palette=\"Set3\")\n",
    "sns.set(font_scale=1.5)\n",
    "ax.set_ylim(top = 150000)\n",
    "ax.set_xlabel(' ')\n",
    "ax.set_ylabel(' ')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,5)\n",
    "ax.set_ylim(top=160000)\n",
    "\n",
    "add_freq()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh\n",
    "\n",
    "def percentile_based_outlier(data, threshold=95):\n",
    "    diff = (100 - threshold) / 2.0\n",
    "    (minval, maxval) = np.percentile(data, [diff, 100 - diff])\n",
    "    return ((data < minval) | (data > maxval))\n",
    "\n",
    "\n",
    "def std_div(data, threshold=3):\n",
    "    std = data.std()\n",
    "    mean = data.mean()\n",
    "    isOutlier = []\n",
    "    for val in data:\n",
    "        if val/std > threshold:\n",
    "            isOutlier.append(True)\n",
    "        else:\n",
    "            isOutlier.append(False)\n",
    "    return isOutlier\n",
    "\n",
    "def outlierVote(data):\n",
    "    x = percentile_based_outlier(data)\n",
    "    y = mad_based_outlier(data)\n",
    "    z = std_div(data)\n",
    "    temp = zip(data.index, x, y, z)\n",
    "    final = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i].count(False) >= 2:\n",
    "            final.append(False)\n",
    "        else:\n",
    "            final.append(True)\n",
    "    return final\n",
    "\n",
    "def plotOutlier(x):\n",
    "    fig, axes = plt.subplots(nrows=4)\n",
    "    for ax, func in zip(axes, [percentile_based_outlier, mad_based_outlier, std_div, outlierVote]):\n",
    "        sns.distplot(x, ax=ax, rug=True, hist=False)\n",
    "        outliers = x[func(x)]\n",
    "        ax.plot(outliers, np.zeros_like(outliers), 'ro', clip_on=False)\n",
    "\n",
    "    kwargs = dict(y=0.95, x=0.05, ha='left', va='top', size=20)\n",
    "    axes[0].set_title('Percentile-based Outliers', **kwargs)\n",
    "    axes[1].set_title('MAD-based Outliers', **kwargs)\n",
    "    axes[2].set_title('STD-based Outliers', **kwargs)\n",
    "    axes[3].set_title('Majority vote based Outliers', **kwargs)\n",
    "    fig.suptitle('Comparing Outlier Tests with n={}'.format(len(x)), size=20)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15,10)\n",
    "    \n",
    "def plotOutlierFree(x):\n",
    "    fig, axes = plt.subplots(nrows=4)\n",
    "    nOutliers = []\n",
    "    for ax, func in zip(axes, [percentile_based_outlier, mad_based_outlier, std_div, outlierVote]):\n",
    "        tfOutlier = zip(x, func(x))\n",
    "        nOutliers.append(len([index for (index, bol) in tfOutlier if bol == True]))\n",
    "        outlierFree = [index for (index, bol) in tfOutlier if bol == True]\n",
    "        sns.distplot(outlierFree, ax=ax, rug=True, hist=False)\n",
    "        \n",
    "    kwargs = dict(y=0.95, x=0.05, ha='left', va='top', size=15)\n",
    "    axes[0].set_title('Percentile-based Outliers, removed: {r}'.format(r=nOutliers[0]), **kwargs)\n",
    "    axes[1].set_title('MAD-based Outliers, removed: {r}'.format(r=nOutliers[1]), **kwargs)\n",
    "    axes[2].set_title('STD-based Outliers, removed: {r}'.format(r=nOutliers[2]), **kwargs)\n",
    "    axes[3].set_title('Majority vote based Outliers, removed: {r}'.format(r=nOutliers[3]), **kwargs)\n",
    "    fig.suptitle('Outlier Removed By Method with n={}'.format(len(x)), size=20)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15,10)\n",
    "\n",
    "def outlierRatio(data):\n",
    "    functions = [percentile_based_outlier, mad_based_outlier, std_div, outlierVote]\n",
    "    outlierDict = {}\n",
    "    for func in functions:\n",
    "        funcResult = func(data)\n",
    "        count = 0\n",
    "        for val in funcResult:\n",
    "            if val == True:\n",
    "                count += 1 \n",
    "        outlierDict[str(func)[10:].split()[0]] = [count, '{:.2f}%'.format((float(count)/len(data))*100)]\n",
    "    \n",
    "    return outlierDict\n",
    "\n",
    "def replaceOutlier(data, method = outlierVote, replace='median'):\n",
    "    '''replace: median (auto)\n",
    "                'minUpper' which is the upper bound of the outlier detection'''\n",
    "    vote = outlierVote(data)\n",
    "    x = pd.DataFrame(zip(data, vote), columns=['debt', 'outlier'])\n",
    "    if replace == 'median':\n",
    "        replace = x.debt.median()\n",
    "    elif replace == 'minUpper':\n",
    "        replace = min([val for (val, vote) in zip(data, vote) if vote == True])\n",
    "        if replace < data.mean():\n",
    "            return 'There are outliers lower than the sample mean'\n",
    "    debtNew = []\n",
    "    for i in range(x.shape[0]):\n",
    "        if x.iloc[i][1] == True:\n",
    "            debtNew.append(replace)\n",
    "        else:\n",
    "            debtNew.append(x.iloc[i][0])\n",
    "    \n",
    "    return debtNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RevolvingUtilizationOfUnsecuredLines var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOutlier(data.RevolvingUtilizationOfUnsecuredLines.sample(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nature of the variable allows coding every extreme value as a fixed number without losing to much predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revNew = []\n",
    "for val in data.RevolvingUtilizationOfUnsecuredLines:\n",
    "    if val <= 2:\n",
    "        revNew.append(val)\n",
    "    else:\n",
    "        revNew.append(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RevolvingUtilizationOfUnsecuredLines = revNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16,30):\n",
    "    print i, len(data[data.age < i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22 is the youngest age in the data one outlier at 0\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageNew = []\n",
    "for val in data.age:\n",
    "    if val > 22:\n",
    "        ageNew.append(val)\n",
    "    else:\n",
    "        ageNew.append(22)\n",
    "        \n",
    "data.age = ageNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumberOfTime3059DaysPastDueNotWorse var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(data.NumberOfTime3059DaysPastDueNotWorse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New = []\n",
    "med = data.NumberOfTime3059DaysPastDueNotWorse.median()\n",
    "for val in data.NumberOfTime3059DaysPastDueNotWorse:\n",
    "    if ((val == 98) | (val == 96)):\n",
    "        New.append(med)\n",
    "    else:\n",
    "        New.append(val)\n",
    "\n",
    "data.NumberOfTime3059DaysPastDueNotWorse = New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DebtRatio var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierRatio(data.DebtRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOutlier(data.DebtRatio.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(mad_based_outlier(data.DebtRatio))\n",
    "add_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minUpperBound = min([val for (val, out) in zip(data.DebtRatio, mad_based_outlier(data.DebtRatio)) if out == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDebtRatio = []\n",
    "for val in data.DebtRatio:\n",
    "    if val > minUpperBound:\n",
    "        newDebtRatio.append(minUpperBound)\n",
    "    else:\n",
    "        newDebtRatio.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.DebtRatio = newDebtRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.DebtRatio.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly income var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOutlier(data.MonthlyIncome.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOutlierFree(data.MonthlyIncome.sample(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outlier from the Monthly income col by outlierVote classifier and replace them with a high fixed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomeNew = replaceOutlier(data.MonthlyIncome, replace='minUpper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MonthlyIncome = incomeNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumberOfTimes90DaysLate var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = removeSpecificAndPutMedian(data.NumberOfTimes90DaysLate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.NumberOfTimes90DaysLate = new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumberRealEstateLoansOrLines var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realNew = []\n",
    "for val in data.NumberRealEstateLoansOrLines:\n",
    "    if val > 17:\n",
    "        realNew.append(17)\n",
    "    else:\n",
    "        realNew.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.NumberRealEstateLoansOrLines = realNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumberOfTime6089DaysPastDueNotWorse var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = removeSpecificAndPutMedian(data.NumberOfTime6089DaysPastDueNotWorse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.NumberOfTime6089DaysPastDueNotWorse = new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumberOfDependents var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depNew = []\n",
    "for var in data.NumberOfDependents:\n",
    "    if var > 10:\n",
    "        depNew.append(10)\n",
    "    else:\n",
    "        depNew.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.NumberOfDependents = depNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NA count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naCount(data):\n",
    "    naCount = {}\n",
    "    for col in data.columns:\n",
    "        colNa = 0\n",
    "        for val in data[col].isnull():\n",
    "            if val == True:\n",
    "                colNa += 1\n",
    "        naCount[col] = [colNa, '{:0.2f}%'.format((float(colNa)/len(data))*100)]\n",
    "\n",
    "    return naCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cvDictGen(functions, scr, X_train=X_train, y_train=y_train, cv=3, verbose=1):\n",
    "    cvDict = {}\n",
    "    for func in functions:\n",
    "        cvScore = cross_val_score(func, X_train, y_train, cv=cv, verbose=verbose, scoring=scr)\n",
    "        cvDict[str(func).split('(')[0]] = [cvScore.mean(), cvScore.std()]\n",
    "    \n",
    "    return cvDict\n",
    "\n",
    "def cvDictNormalize(cvDict):\n",
    "    cvDictNormalized = {}\n",
    "    for key in cvDict.keys():\n",
    "        for i in cvDict[key]:\n",
    "            cvDictNormalized[key] = ['{:0.2f}'.format((cvDict[key][0]/cvDict[cvDict.keys()[0]][0])),\n",
    "                                     '{:0.2f}'.format((cvDict[key][1]/cvDict[cvDict.keys()[0]][1]))]\n",
    "    return cvDictNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumberOfDependents NA replacment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depNew = []\n",
    "med = data.NumberOfDependents.median()\n",
    "for val in data.NumberOfDependents:\n",
    "    if val.is_integer() == False:\n",
    "        depNew.append(med)\n",
    "    else:\n",
    "        depNew.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.NumberOfDependents = depNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model to predict NA values from the data and plug them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.MonthlyIncome.isnull() == False]\n",
    "test = data[data.MonthlyIncome.isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['MonthlyIncome', 'SeriousDlqin2yrs'], axis=1)\n",
    "y_train = train.MonthlyIncome\n",
    "X_test = test.drop(['MonthlyIncome', 'SeriousDlqin2yrs'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.grid_search import RandomizedSearchCV \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmMod = LinearRegression(fit_intercept=True, normalize=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adaMod = AdaBoostRegressor(base_estimator=None, n_estimators=100, learning_rate=1.0, loss='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbMod = GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=300, subsample=1.0, min_samples_split=2,\n",
    "                                  min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None,\n",
    "                                  random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None,\n",
    "                                  warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfMod = RandomForestRegressor(n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                              min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True,\n",
    "                              oob_score=False, n_jobs=1, random_state=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnMod = KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                             p=2, metric='minkowski', metric_params=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Normalize the CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDictNormalize(cvDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace NA in monthly income with the predicted values from the linear regression as it did pretty well compared to the other, more computationly expencive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lmMod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predNoZero = []\n",
    "for val in pred:\n",
    "    if val >= 0:\n",
    "        predNoZero.append(val)\n",
    "    else:\n",
    "        predNoZero.append(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFull = data[data.MonthlyIncome.isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFull['MonthlyIncome'] = predNoZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monNew = []\n",
    "for index in data.index:\n",
    "    if data.MonthlyIncome[index].is_integer() == True:\n",
    "        monNew.append(data.MonthlyIncome[index])\n",
    "    else:\n",
    "        monNew.append(testFull.MonthlyIncome[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MonthlyIncome = monNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('SeriousDlqin2yrs', axis=1)\n",
    "y = data.SeriousDlqin2yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sScaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "xScaled = sScaler.fit_transform(X_train)\n",
    "\n",
    "forPca = pd.DataFrame(xScaled)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pcaMod = PCA(n_components=2)\n",
    "\n",
    "xPca = pcaMod.fit_transform(X)\n",
    "\n",
    "xPcaDataframe = pd.DataFrame(xPca, columns=['PC1', 'PC2'])\n",
    "\n",
    "xPcaDataframe['cat'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data = xPcaDataframe, x='PC2', y='PC1', hue='cat', size=10, aspect=20, fit_reg=False,\n",
    "               scatter_kws={'alpha': 0.3})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xScaled = minmax_scale(X, feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaMod = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto', priors=None, n_components=2,\n",
    "                                    store_covariance=False, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedLdaMod = ldaMod.fit(xScaled, y).transform(xScaled)\n",
    "\n",
    "ldaDf = pd.DataFrame(fittedLdaMod, columns=['one', 'two'])\n",
    "\n",
    "ldaDf['cat'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data = ldaDf, x='one', y='two', hue='cat', size=30, aspect=5, fit_reg=False, scatter_kws={'alpha': 0.3})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModS = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto', priors=None, n_components=2,\n",
    "                                    store_covariance=False, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedLdaModS = ldaModS.fit(xScaled, y).transform(xScaled)\n",
    "\n",
    "ldaDfS = pd.DataFrame(fittedLdaModS, columns=['one', 'two'])\n",
    "\n",
    "ldaDfS['cat'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data = ldaDf, x='one', y='two', hue='cat', size=50, aspect=5, fit_reg=False, scatter_kws={'alpha': 0.3})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsneMod = TSNE(n_components=2, perplexity=30.0, early_exaggeration=4.0, learning_rate=50., n_iter=500,\n",
    "               metric='euclidean', init='random', verbose=2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7000\n",
    "X_data, X_none, y_data, y_none = train_test_split(X, y, test_size=(1-(n/float(len(data)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTsne = tsneMod.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTsneDataFrame = pd.DataFrame(xTsne, columns=['one', 'two'])\n",
    "\n",
    "y_data.index = range(0,len(xTsneDataFrame))\n",
    "\n",
    "xTsneDataFrame['cat'] = y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data = xTsneDataFrame, x='one', y='two', hue='cat', size=70, aspect=5, fit_reg=False, palette='Set2',\n",
    "               scatter_kws={\"s\": 50, 'alpha': 0.5})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knMod = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2,\n",
    "                             metric='minkowski', metric_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmMod = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True,\n",
    "                            intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100,\n",
    "                            multi_class='ovr', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaMod = AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbMod = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=1.0,\n",
    "                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3,\n",
    "                                   init=None, random_state=None, max_features=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfMod = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                               max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvD = cvDictGen(functions=[knMod, glmMod, adaMod, gbMod, rfMod], scr='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDictNormalize(cvD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB and ADA seem to preform the best out-of-the-box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaHyperParams = {'n_estimators': [10,50,100,200,400]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gridSearchAda = RandomizedSearchCV(estimator=adaMod, param_distributions=adaHyperParams, n_iter=5,\n",
    "                                   scoring='roc_auc', fit_params=None, cv=None, verbose=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchAda.best_params_, gridSearchAda.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbHyperParams = {'loss' : ['deviance', 'exponential'],\n",
    "                 'n_estimators': randint(10, 500),\n",
    "                 'max_depth': randint(1,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gridSearchGB = RandomizedSearchCV(estimator=gbMod, param_distributions=gbHyperParams, n_iter=10,\n",
    "                                   scoring='roc_auc', fit_params=None, cv=None, verbose=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchGB.best_params_, gridSearchGB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the best GB and ADA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGbModFitted = gridSearchGB.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAdaModFitted = gridSearchAda.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDictHPO = cvDictGen(functions=[bestGbModFitted, bestAdaModFitted], scr='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDictNormalize(cvDictHPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curve with CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plotCvRocCurve** will plot the CV ROC curve with nfolds\n",
    "\n",
    "**rocZeroOne** will compute the best cut-off point for the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCvRocCurve(X, y, classifier, nfolds=5):\n",
    "    \n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import interp\n",
    "\n",
    "    cv = StratifiedKFold(y, n_folds=nfolds)\n",
    "\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = classifier.fit(X.iloc[train], y.iloc[train]).predict_proba(X.iloc[test])\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y.iloc[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "             label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('CV ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15,5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def rocZeroOne(y_true, y_predicted_porba):\n",
    "    \n",
    "    from sklearn.metrics import roc_curve\n",
    "    from scipy.spatial.distance import euclidean\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_predicted_porba[:, 1])\n",
    "    \n",
    "    best = [0, 1]\n",
    "    dist = []\n",
    "    for (x, y) in zip(fpr, tpr):\n",
    "        dist.append([euclidean([x,y], best)])\n",
    "\n",
    "    bestPoint = [fpr[dist.index(min(dist))], tpr[dist.index(min(dist))]]\n",
    "    \n",
    "    bestCutOff1 = thresholds[list(fpr).index(bestPoint[0])]\n",
    "    bestCutOff2 = thresholds[list(tpr).index(bestPoint[1])]\n",
    "    \n",
    "    print '\\n' + 'Best point on the ROC: TPR = {:0.3f}%, FPR = {:0.3f}%'.format(bestPoint[1]*100, bestPoint[0]*100)\n",
    "    print '\\n' + 'Best Cut-Off point: {:0.4f}'.format(bestCutOff1)\n",
    "\n",
    "    plt.plot(dist)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Euclidean Distance to the perfect [0,1]')\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCvRocCurve(X, y, gridSearchGB.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocZeroOne(y_test, bestGbModFitted.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCvRocCurve(X, y, gridSearchAda.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocZeroOne(y_test, bestAdaModFitted.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title = 'Confusion matrix', cmap=plt.cm.Blues):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print 'Classification Report:\\n'\n",
    "    print classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    def plot_confusion_matrix_plot(cm, title = 'Confusion matrix', cmap=plt.cm.Blues):\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(y_test.unique()))\n",
    "        plt.xticks(tick_marks, rotation=45)\n",
    "        plt.yticks(tick_marks)\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "    \n",
    "    print '\\n Confusion matrix, without normalization: \\n'\n",
    "    print cm\n",
    "    plot_confusion_matrix_plot(cm=cm)\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print('\\n Normalized confusion matrix \\n')\n",
    "    print(cm_normalized)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix_plot(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "def makePredThresh(fittedCls, thr = 0.5, X_test=X_test):\n",
    "    prob = fittedCls.predict_proba(X_test)[: ,1]\n",
    "    final = []\n",
    "    for p in prob:\n",
    "        if p >= thr:\n",
    "            final.append(1)\n",
    "        else:\n",
    "            final.append(0)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predicions from the GB model with the optimal threshold calculated before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = makePredThresh(bestGbModFitted, thr=0.0645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions from the ADA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predAda = makePredThresh(bestAdaModFitted, thr=0.4982)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, predAda)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": false,
   "environment": null,
   "summary": "Credit Score ML algo",
   "url": "https://anaconda.org/idoz/credit-score"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
