---
title: "Credit Risk Analysis"
author: "Dr. Juliho Castillo"
date: "6 de septiembre de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction and data preprocessing

## The Data

```{r}
loan_data <- readRDS("./data/loan_data_ch1.rds")
head(loan_data,10)
```
## CrossTable
```{r}
library(gmodels)
CrossTable(loan_data$home_ownership)
```

```{r}
CrossTable(loan_data$home_ownership, loan_data$loan_status, prop.r = TRUE,
           prop.c = FALSE, prop.t = FALSE, prop.chisq = FALSE)
```

### Exploring the credit data

View the structure of loan_data
```{r}
library(dplyr)
glimpse(loan_data)
```

Call CrossTable() on loan_status
```{r}
CrossTable(loan_data$loan_status)
```

Call CrossTable() on grade and loan_status
```{r}
CrossTable(loan_data$grade, loan_data$loan_status, prop.r=T, prop.c=F, prop.t=F, prop.chisq=F)
```

The proportion of defaults increases when the credit rating moves from A to G

## Histogram and outliers

using function  `hist()` 

```{r}
library(ggplot2)
ggplot(loan_data, aes(x=int_rate)) +
  geom_histogram( ) +
  ggtitle("Histogram of interest rate") +
  xlab("Interest rate")
```

Using function `hist()` on `annual_inc`

```{r}
ggplot(loan_data, aes(x=annual_inc)) +
  geom_histogram() +
  xlab("Annual Income") +
  ggtitle("Histogram of Annual Income")
```

```{r}
n_ <- sqrt(nrow(loan_data)) 
m = min(loan_data$annual_inc)
M = max(loan_data$annual_inc)
n_breaks = seq(m,M,(M-m)/(n_-1))

hist_income_n <- ggplot(loan_data, aes(x=annual_inc)) +
  geom_histogram(breaks=n_breaks ) 

hist_income_n
```

```{r}
ggplot(loan_data, aes(x=1, y=(annual_inc))) +
  geom_boxplot()
```


```{r}
ggplot(loan_data, aes(x=1, y=log(annual_inc))) +
  geom_boxplot()
```

Expert judgement vs Rule Of Thum

* “Annual salaries > $ 3 million are outliers”
```{r}
loan_data_expert <- loan_data %>%
  filter(annual_inc <= 3*10^6)

n = nrow(loan_data_expert)
l = sqrt(n)

ggplot(loan_data_expert, aes(x = annual_inc)) +
  geom_histogram(binwidth = l)
```

* Use of a rule of thumb: outlier if bigger than Q3 + 1.5 * IQR
```{r}
outlier_cutoff <- quantile(loan_data$annual_inc, 0.75) + 1.5*IQR(loan_data$annual_inc) 

loan_data_ROT <- loan_data %>%
  filter(annual_inc <= outlier_cutoff)

n = nrow(loan_data_ROT)
l = sqrt(n)


ggplot(loan_data_ROT, aes(x = annual_inc)) +
  geom_histogram(binwidth = l)
```

## Missing Data and Coarse Classifitacion

```{r}
summary(loan_data_ROT)
#### me!
#loan_data <- loan_data_ROT
loan_data <- loan_data_expert
####
summary(loan_data$emp_length)
nrow(loan_data)
```

### Missing inputs: strategies
* Delete row/column
* Replace
* Keep

### Delete rows

```{r}
index_NA <- which(is.na(loan_data$emp_length))
loan_data_no_NA <- loan_data[-c(index_NA), ]
```

### Delete column

```{r}
loan_data_delete_employ <- loan_data
loan_data_delete_employ$emp_length <- NULL
```

### Replace: median imputation

```{r}
index_NA <- which(is.na(loan_data$emp_length))
loan_data_replace <- loan_data
loan_data_replace$emp_length[index_NA] <- median(loan_data$emp_length, na.rm = TRUE)
```

### Keep!!!

```{r}
my_func <- function(x) {
  if (is.na(x)) {
    return("Missing")
  } else if(0<=x & x<15) {
    return("0-15")
  } else if(15<=x & x<30) {
    return("15-30")
  } else if(30<=x & x<45) {
    return("30-45")
  } else {
    return("45+")
  }
  
}

temp <- loan_data$emp_length
#print(temp)
loan_data$emp_length <- NULL
print(loan_data$emp_lenght)

loan_data$emp_cat <- sapply(temp, my_func)
loan_data$emp_cat <- as.factor(loan_data$emp_cat)

str(loan_data)
summary(loan_data)
```


### Deleting missing data

```{r}
# Look at summary of loan_data
print(summary(loan_data$int_rate))

# Get indices of missing interest rates: na_index
na_index <- which(is.na(loan_data$int_rate))

# Remove observations with missing interest rates: loan_data_delrow_na
loan_data_delrow_na <- loan_data[-na_index, ]
print(summary(loan_data_delrow_na$int_rate))

# Make copy of loan_data
loan_data_delcol_na <- loan_data

# Delete interest rate column from loan_data_delcol_na
loan_data_delcol_na$int_rate <- NULL
print(summary(loan_data_delcol_na$int_rate))
```

### Replacing missing data

```{r}
# Compute the median of int_rate
median_ir <- median(loan_data$int_rate, na.rm=T)

# Make copy of loan_data
loan_data_replace <- loan_data

# Replace missing interest rates with median
loan_data_replace$int_rate[na_index] <- median_ir

# Check if the NAs are gone
summary(loan_data_replace$int_rate)
```

### Keeping missing data
```{r}
# Make the necessary replacements in the coarse classification example below 
loan_data$ir_cat <- rep(NA, length(loan_data$int_rate))

loan_data$ir_cat[which(loan_data$int_rate <= 8)] <- "0-8"
loan_data$ir_cat[which(loan_data$int_rate > 8 & loan_data$int_rate <= 11)] <- "8-11"
loan_data$ir_cat[which(loan_data$int_rate > 11 & loan_data$int_rate <= 13.5)] <- "11-13.5"
loan_data$ir_cat[which(loan_data$int_rate > 13.5)] <- "13.5+"
loan_data$ir_cat[which(is.na(loan_data$int_rate))] <- "Missing"

loan_data$ir_cat <- as.factor(loan_data$ir_cat)

# Look at your new variable using plot()
plot(loan_data$ir_cat)
print(levels(loan_data$ir_cat))
```

```{r}
loan_data$int_rate <- NULL
```


## Data splitting and confusion matrices

### Splitting the data set
```{r}
# Set seed of 567
set.seed(567)

# Store row numbers for training set: index_train
index_train <- sample(1:nrow(loan_data), 2/3*nrow(loan_data))

# Create training set: training_set
training_set <- loan_data[index_train, ]

# Create test set: test_set
test_set <- loan_data[-index_train, ]
```

### Creating a confusion matrix
```{r}
#Simulate a model
X <- length(test_set$loan_status)
Dls <- sample(c(0,0,0,0,1), replace=TRUE, size=X)
model_pred <- test_set$loan_status+Dls

# Create confusion matrix
conf_matrix <- table(test_set$loan_status, model_pred)

# Compute classification accuracy
(conf_matrix[2,2]+conf_matrix[1,1])/sum(conf_matrix)

# Compute sensitivity
conf_matrix[2,2]/sum(conf_matrix[2,])
```

# Logistic regression
## Logistic regression: introduction

### Basic logistic regression
```{r}
# Build a glm model with variable ir_cat as a predictor
log_model_cat <- glm(loan_status ~ ir_cat, family = "binomial", data = training_set)


# Print the parameter estimates 
log_model_cat

# Look at the different categories in ir_cat using table()
table(loan_data$ir_cat)
```

### Interpreting the odds for a categorical variable

How do you interpret the parameter estimate for the interest rates that are between 8% and 11%? You can use the console to make basic computations (if necessary). 
```{r}
log_model_cat$coefficients
```
Compared to the reference category with interest rates between 0% and 8%, the odds in favor of default change by a multiple of... 1.718

### Multiple variables in a logistic regression model

```{r}
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade +loan_amnt + annual_inc,family = "binomial", data = training_set)


# Obtain significance levels using summary()
summary(log_model_multi)
```

### Interpreting significance levels

Have a look at the significance levels of your latest model log_model_multi, which is loaded in the workspace. Go through the summary() again. 

```{r}
summary(log_model_multi)
```


Which of the following quotes is correct? The parameter estimates for loan_amount and annual_inc are...

**Of the same order, however, annual_inc is statistically significant where loan_amount is not.**

## Logistic regression: predicting the probability of default

```{r}
log_model_small <- glm(loan_status ~ age + home_ownership, family = "binomial", data = training_set)

log_model_small
```

### Making predictions in R

```{r}
test_case <- as.data.frame(test_set[1,])
print(test_case)

predict(log_model_small, newdata = test_case)

predict(log_model_small, newdata = test_case, type = "response")
```


### Predicting the probability of default
```{r}
# Build the logistic regression model
predictions_all_small <- predict(log_model_small, newdata = test_set, type = "response")

# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
```

### Making more discriminative models
```{r}
# Change the code below to construct a logistic regression model using all available predictors in the data set

log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
#log_model_full$xlevels$ir_cat[5] <- "Missing"
summary(log_model_full)

# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type="response")

# Look at the predictions range
print(range(predictions_all_full))
```

## Evaluating the logistic regression model result

### Specifying a cut-off

```{r}
# The code for the logistic regression model and the predictions is given below
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")

# Make a binary predictions-vector using a cut-off of 15%
pred_cutoff_15 <- ifelse(predictions_all_full > 0.15, 1,0)

# Construct a confusion matrix
table(test_set$loan_status, pred_cutoff_15)
```

### Comparing two cut-offs

```{r}
# The code for the logistic regression model and the predictions is given below
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")

# Make a binary predictions-vector using a cut-off of 15%
pred_cutoff_20 <- ifelse(predictions_all_full > 0.20, 1,0)

# Construct a confusion matrix
table(test_set$loan_status, pred_cutoff_20)
```

Accuracy increases, sensitivity decreases and specificity increases.

## Wrap-up and remarks

### Comparing link functions for a given cut-off

```{r}
library(readxl)
temp1 <- read_excel("./true_values.xlsx", col_names = FALSE)
true_val <- temp1$X__1
print(length(true_val))
```


```{r}
# Fit the logit, probit and cloglog-link logistic regression models
#print(length(training_set))

log_model_logit <- glm(loan_status ~ age + emp_cat + ir_cat + loan_amnt,
                       family = binomial(link = logit), data = training_set)
log_model_probit <- glm(loan_status ~ age + emp_cat + ir_cat + loan_amnt,
                       family = binomial(link = probit), data = training_set)

log_model_cloglog <- glm(loan_status ~ age + emp_cat + ir_cat + loan_amnt,
                       family = binomial(link = cloglog), data = training_set)
  
# Make predictions for all models using the test set

#print(length(test_set))

predictions_logit <- predict(log_model_logit, newdata = test_set, type = "response")
predictions_probit <- predict(log_model_probit, newdata = test_set, type = "response")
predictions_cloglog <- predict(log_model_cloglog, newdata = test_set, type = "response")

#print(length(predictions_logit))
  
# Use a cut-off of 14% to make binary predictions-vectors
cutoff <- 0.14
class_pred_logit <- ifelse(predictions_logit > cutoff, 1, 0)
class_pred_probit <- ifelse(predictions_probit > cutoff, 1, 0)
class_pred_cloglog <- ifelse(predictions_cloglog > cutoff, 1, 0)

#print(length(class_pred_logit))
  
# Make a confusion matrix for the three models
tab_class_logit <- table(true_val,class_pred_logit)
tab_class_probit <- table(true_val,class_pred_probit)
tab_class_cloglog <- table(true_val,class_pred_cloglog)
  
# Compute the classification accuracy for all three models
(acc_logit <- sum(diag(tab_class_logit)) / nrow(test_set))
(acc_probit <- sum(diag(tab_class_probit)) / nrow(test_set))
(acc_cloglog <- sum(diag(tab_class_cloglog)) / nrow(test_set))
```

# Decision trees

## What is a decision tree?

## Computing the gain for a tree (incompleto)

```{r}
# The Gini-measure of the root node is given below
gini_root <- 2 * 89 / 500 * 411 / 500

# Compute the Gini measure for the left leaf node
gini_ll <- 2 * 401/(401+45) * 45/(401+45)

# Compute the Gini measure for the right leaf node
gini_rl <- 2 * 10/(10+44) * 44/(10+44)

# Compute the gain
gain <- gini_root - 446 / 500 * gini_ll - 54 / 500 * gini_rl

# compare the gain-column in small_tree$splits with our computed gain, multiplied by 500, and assure they are the same
#small_tree$splits
improve <- gain * 500
```

## Building decision trees using the rpart package

### rpart() package! 

```{r}
library(rpart)
```


But…
* hard building nice decision tree for credit risk data
* main reason: unbalanced data

```{r}
fit_default <- rpart(loan_status ~ ., method = "class", data = training_set)
```

```{r}
# become an error!
## plot(fit_default)
```

### Undersampling the training set

I need to create the undersampled training set, but I think it's straightforward and not that importat. 

```
# Load package rpart in your workspace.
#library(rpart)

# Change the code provided in the video such that a decision tree is constructed using the undersampled training set. Include rpart.control to relax the complexity parameter to 0.001.
tree_undersample <- rpart(loan_status ~ ., method = "class",
                          data =  undersampled_training_set, control = rpart.control(cp = 0.001))

# Plot the decision tree
plot(tree_undersample, uniform = T)

# Add labels to the decision tree
text(tree_undersample)
```

### Changing the prior probabilities

```{r}
# Change the code below such that a tree is constructed with adjusted prior probabilities.
tree_prior <- rpart(loan_status ~ ., method = "class",
                    data = training_set, parms = list(prior = c(0.7, 0.3)),
                    control = rpart.control(cp = 0.001))

# Plot the decision tree
plot(tree_prior, uniform = TRUE)

# Add labels to the decision tree
text(tree_prior)
```

### Including a loss matrix

```{r}
# Change the code below such that a decision tree is constructed using a loss matrix penalizing 10 times more heavily for misclassified defaults.
tree_loss_matrix <- rpart(loan_status ~ ., method = "class",
                          data =  training_set, parms = list(loss = matrix(c(0, 10, 1, 0), ncol=2)), 
                          control = rpart.control(cp=0.001))
                          

# Plot the decision tree
plot(tree_loss_matrix, uniform = T)

# Add labels to the decision tree
text(tree_loss_matrix)
```

## Pruning the decision tree

### Pruning the tree with changed prior probabilities

```{r}
# tree_prior is loaded in your workspace

# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)

# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized
printcp(tree_prior)

# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[, "xerror"])

# Create tree_min
tree_min <- tree_prior$cptable[index, "CP"]

#  Prune the tree using tree_min
ptree_prior <- prune(tree_prior, cp = tree_min)

# Use prp() to plot the pruned tree
library(rpart.plot)
prp(ptree_prior)
```

### Pruning the tree with the loss matrix

```{r}
# set a seed and run the code to construct the tree with the loss matrix again
set.seed(345)
tree_loss_matrix  <- rpart(loan_status ~ ., method = "class", data = training_set,
                           parms = list(loss=matrix(c(0, 10, 1, 0), ncol = 2)),
                           control = rpart.control(cp = 0.001))

# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_loss_matrix)

# Prune the tree using cp = 0.0012788
ptree_loss_matrix <- prune(tree_loss_matrix, cp=0.0012788)

# Use prp() and argument extra = 1 to plot the pruned tree
prp(ptree_loss_matrix, extra=1)
```

## Other tree options and confusion matrices

### One final tree using more options

```{r}
case_weights_excel <- read_excel("./case_weights.xlsx", col_names = FALSE)

case_weights <- case_weights_excel$X__1 

# set a seed and run the code to obtain a tree using weights, minsplit and minbucket
set.seed(345)
tree_weights <- rpart(loan_status ~ ., method = "class",
                      data = training_set, weights = case_weights,
                      control = rpart.control(minsplit = 5, minbucket = 2, cp = 0.001))

# Plot the cross-validated error rate for a changing cp
plotcp(tree_weights)

# Create an index for of the row with the minimum xerror
index <- which.min(tree_weights$cp[ , "xerror"])

# Create tree_min
tree_min <- tree_weights$cp[index, "CP"]

# Prune the tree using tree_min
ptree_weights <- prune(tree_weights, cp = tree_min)

# Plot the pruned tree using the rpart.plot()-package
prp(ptree_weights, extra = 1)
```

### Confusion matrices and accuracy of our final trees

```{r}
# Make predictions for each of the pruned trees using the test set.
#pred_undersample <- predict(ptree_undersample, newdata = test_set,  type = "class")
pred_prior <- predict(ptree_prior, newdata = test_set,  type = "class")
pred_loss_matrix <- predict(ptree_loss_matrix, newdata = test_set,  type = "class")
pred_weights <- predict(ptree_weights, newdata = test_set,  type = "class")

# construct confusion matrices using the predictions.
#confmat_undersample <- table(test_set$loan_status, pred_undersample)
confmat_prior <- table(test_set$loan_status, pred_prior)
confmat_loss_matrix <- table(test_set$loan_status, pred_loss_matrix)
confmat_weights <- table(test_set$loan_status, pred_weights)

# Compute the accuracies
#(acc_undersample <- sum(diag(confmat_undersample)) / nrow(test_set))
(acc_prior <- sum(diag(confmat_prior)) / nrow(test_set))
(acc_loss_matrix <- sum(diag(confmat_loss_matrix)) / nrow(test_set))
(acc_weights <- sum(diag(confmat_weights)) / nrow(test_set))
```

# Evaluating a credit risk model

## Finding the right cut-off: the strategy curve

### Computing a bad rate given a fixed acceptance rate
```{r}
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]

# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 0.8)  

# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)

# Obtain the actual default status for the accepted loans
accepted_status_prior_80 <- test_set$loan_status[bin_pred_prior_80 == 0]

# Obtain the bad rate for the accepted loans
bad_rate <- sum(accepted_status_prior_80)/length(accepted_status_prior_80)
bad_rate
```

### The strategy table and strategy curve

```{r}
# Have a look at the function strategy_bank
strategy_bank <- function(prob_of_def){
cutoff=rep(NA, 21)
bad_rate=rep(NA, 21)
accept_rate=seq(1,0,by=-0.05)
for (i in 1:21){
  cutoff[i]=quantile(prob_of_def,accept_rate[i])
  pred_i=ifelse(prob_of_def> cutoff[i], 1, 0)
  pred_as_good=test_set$loan_status[pred_i==0]
  bad_rate[i]=sum(pred_as_good)/length(pred_as_good)}
table=cbind(accept_rate,cutoff=round(cutoff,4),bad_rate=round(bad_rate,4))
return(list(table=table,bad_rate=bad_rate, accept_rate=accept_rate, cutoff=cutoff))
}
print(strategy_bank)

# Apply the function strategy_bank to both predictions_cloglog and predictions_loss_matrix
strategy_cloglog <- strategy_bank(predictions_cloglog)
predictions_loss_matrix <- as.numeric(pred_loss_matrix)
strategy_loss_matrix <- strategy_bank(predictions_loss_matrix)

# Obtain the strategy tables for both prediction-vectors
strategy_cloglog$table
strategy_loss_matrix$table

# Plot the strategy functions
par(mfrow = c(1,2))
plot(strategy_cloglog$accept_rate, strategy_cloglog$bad_rate, 
     type = "l", xlab = "Acceptance rate", ylab = "Bad rate", 
     lwd = 2, main = "logistic regression")

plot(strategy_loss_matrix$accept_rate, strategy_loss_matrix$bad_rate, 
     type = "l", xlab = "Acceptance rate", 
     ylab = "Bad rate", lwd = 2, main = "tree")
print(strategy_bank)

# Apply the function strategy_bank to both predictions_cloglog and predictions_loss_matrix
strategy_cloglog <- strategy_bank(predictions_cloglog)
strategy_loss_matrix <- strategy_bank(predictions_loss_matrix)

# Obtain the strategy tables for both prediction-vectors
strategy_cloglog$table
strategy_loss_matrix$table

# Plot the strategy functions
par(mfrow = c(1,2))
plot(strategy_cloglog$accept_rate, strategy_cloglog$bad_rate, 
     type = "l", xlab = "Acceptance rate", ylab = "Bad rate", 
     lwd = 2, main = "logistic regression")

plot(strategy_loss_matrix$accept_rate, strategy_loss_matrix$bad_rate, 
     type = "l", xlab = "Acceptance rate", 
     ylab = "Bad rate", lwd = 2, main = "tree")
```

## To tree or not to tree?
Imagine you have 2 banks: Bank A, and Bank B. These banks are restricted to using a certain acceptance rate.

Bank A has to use an acceptance rate of 45%
Bank B has to use an acceptance rate of 85%
Based on the strategy tables, which model will Bank A and Bank B prefer to use?

Do not hesitate to have a look at the tables again. They are loaded in your workspace as `strategy_cloglog$table` and `strategy_loss_matrix$table`

```{r}
print(strategy_cloglog$table)
print(strategy_loss_matrix$table)
```

Bank A will prefer to use the classification tree model, but for Bank B, the logistic regression model leads to lower bad rates.

## The ROC-curve

### ROC-curves for comparison of logistic regression models
```{r}
# Load the pROC-package
library(pROC)

# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
ROC_probit <- roc(test_set$loan_status, predictions_probit)
ROC_cloglog <- roc(test_set$loan_status, predictions_cloglog)
ROC_all_full <- roc(test_set$loan_status, predictions_all_full) 

# Draw all ROCs on one plot
plot(ROC_logit)
lines(ROC_probit, col="blue")
lines(ROC_cloglog, col="red")
lines(ROC_all_full, col="green")

# Compute the AUCs
auc(ROC_logit)
auc(ROC_probit)
auc(ROC_cloglog)
auc(ROC_all_full)
```

### ROC-curves for comparison of tree-based models

```{r}
# Construct the objects containing ROC-information
##ROC_undersample <- roc(test_set$loan_status, predictions_undersample)

predictions_prior <- as.numeric(pred_prior)
predictions_weights <- as.numeric(pred_weights)

ROC_prior <- roc(test_set$loan_status, predictions_prior)
ROC_loss_matrix <- roc(test_set$loan_status, predictions_loss_matrix)  
ROC_weights <- roc(test_set$loan_status, predictions_weights)

# Draw the ROC-curves in one plot
##plot(ROC_undersample)
plot(ROC_prior, col="blue")  
lines(ROC_loss_matrix, col="red")
lines(ROC_weights, col="green")    

# Compute the AUCs
##auc(ROC_undersample)
auc(ROC_prior)
auc(ROC_loss_matrix)
auc(ROC_weights)
```

### Another round of pruning based on AUC

```{r}
# Build four models each time deleting one variable in log_3_remove_ir
log_4_remove_amnt <- glm(loan_status ~ grade + annual_inc + emp_cat, 
                        family = binomial, data = training_set) 
log_4_remove_grade <- glm(loan_status ~ loan_amnt + annual_inc + emp_cat, family = binomial, data = training_set)
log_4_remove_inc <- glm(loan_status ~ loan_amnt + grade + emp_cat, family = binomial, data = training_set)
log_4_remove_emp <- glm(loan_status ~ loan_amnt + grade + annual_inc, family = binomial, data = training_set)

# Make PD-predictions for each of the models
pred_4_remove_amnt <- predict(log_4_remove_amnt, newdata = test_set, type = "response")
pred_4_remove_grade <- predict(log_4_remove_grade, newdata = test_set, type = "response")
pred_4_remove_inc <- predict(log_4_remove_inc, newdata = test_set, type = "response")
pred_4_remove_emp <- predict(log_4_remove_emp, newdata = test_set, type = "response")

# Compute the AUCs
auc(test_set$loan_status, pred_4_remove_amnt)
auc(test_set$loan_status, pred_4_remove_grade)  
auc(test_set$loan_status, pred_4_remove_inc)
auc(test_set$loan_status, pred_4_remove_emp)
```

### Further model reduction?

```{r}
# Build three models each time deleting one variable in log_4_remove_amnt
log_5_remove_grade <- glm(loan_status ~ annual_inc + emp_cat, family = binomial, data = training_set)  
log_5_remove_inc <- glm(loan_status ~ grade  + emp_cat , family = binomial, data = training_set)
log_5_remove_emp <- glm(loan_status ~ grade + annual_inc, family = binomial, data = training_set)

# Make PD-predictions for each of the models
pred_5_remove_grade <- predict(log_5_remove_grade, newdata = test_set, type = "response")
pred_5_remove_inc <- predict(log_5_remove_inc, newdata = test_set, type = "response")
pred_5_remove_emp <- predict(log_5_remove_emp, newdata = test_set, type = "response")

# Compute the AUCs
auc(test_set$loan_status, pred_5_remove_grade)
auc(test_set$loan_status, pred_5_remove_inc)
auc(test_set$loan_status, pred_5_remove_emp)

# Plot the ROC-curve for the best model here
plot(roc(test_set$loan_status,pred_4_remove_amnt))
```

